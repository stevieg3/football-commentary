{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with GloVe embeddings and time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.init import xavier_uniform_\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /cs/student/msc/ml/2020/sgeorge/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Need to specify device so that code can easily run on GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749640, 13)\n",
      "(92689, 13)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet('data/processed/train.parquet')\n",
    "print(train.shape)\n",
    "\n",
    "dev = pd.read_parquet('data/processed/dev.parquet')\n",
    "print(dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>sort_order</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_team</th>\n",
       "      <th>opponent</th>\n",
       "      <th>is_goal</th>\n",
       "      <th>assist_method</th>\n",
       "      <th>fast_break</th>\n",
       "      <th>season</th>\n",
       "      <th>country</th>\n",
       "      <th>event_team_was_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Attempt missed. Mladen Petric (Hamburg) left f...</td>\n",
       "      <td>Attempt</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>0</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Corner,  Borussia Dortmund. Conceded by Dennis...</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Corner,  Borussia Dortmund. Conceded by Heiko ...</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Foul by Sven Bender (Borussia Dortmund).</td>\n",
       "      <td>Foul</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>Gokhan Tore (Hamburg) wins a free kick in the ...</td>\n",
       "      <td>Free kick won</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp  sort_order  time  \\\n",
       "0  UFot0hit/           1     2   \n",
       "1  UFot0hit/           2     4   \n",
       "2  UFot0hit/           3     4   \n",
       "3  UFot0hit/           4     7   \n",
       "4  UFot0hit/           5     7   \n",
       "\n",
       "                                                text     event_type  \\\n",
       "0  Attempt missed. Mladen Petric (Hamburg) left f...        Attempt   \n",
       "1  Corner,  Borussia Dortmund. Conceded by Dennis...         Corner   \n",
       "2  Corner,  Borussia Dortmund. Conceded by Heiko ...         Corner   \n",
       "3           Foul by Sven Bender (Borussia Dortmund).           Foul   \n",
       "4  Gokhan Tore (Hamburg) wins a free kick in the ...  Free kick won   \n",
       "\n",
       "          event_team           opponent  is_goal assist_method  fast_break  \\\n",
       "0         Hamburg SV  Borussia Dortmund        0          Pass           0   \n",
       "1  Borussia Dortmund         Hamburg SV        0          None           0   \n",
       "2  Borussia Dortmund         Hamburg SV        0          None           0   \n",
       "3  Borussia Dortmund         Hamburg SV        0          None           0   \n",
       "4         Hamburg SV  Borussia Dortmund        0          None           0   \n",
       "\n",
       "   season  country  event_team_was_home  \n",
       "0    2012  germany                    0  \n",
       "1    2012  germany                    1  \n",
       "2    2012  germany                    1  \n",
       "3    2012  germany                    1  \n",
       "4    2012  germany                    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# time_min_max_scalar = MinMaxScaler()\n",
    "# time_min_max_scalar.fit(train[['time']])\n",
    "# pickle.dump(time_min_max_scalar, open('models/time_min_max_scalar.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_min_max_scalar = pickle.load(open('models/time_min_max_scalar.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_nlp(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Sort by event order\n",
    "    df.sort_values(['id_odsp', 'sort_order'], inplace=True)\n",
    "    # Create target\n",
    "    df['next_event_is_goal'] = df.groupby('id_odsp')['is_goal'].shift(-1)\n",
    "    # Drop redundant columns\n",
    "    df.drop(\n",
    "        columns=['sort_order', 'event_type', 'event_team', 'opponent', 'assist_method', 'fast_break', 'season', 'country'], \n",
    "        inplace=True\n",
    "    )\n",
    "    # Drop entries with null target due to -1 shift\n",
    "    df.dropna(subset=['next_event_is_goal'], axis=0, inplace=True)\n",
    "    \n",
    "    # Scale time\n",
    "    df['time'] = time_min_max_scalar.transform(df[['time']])\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((742443, 6), (91789, 6))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p = process_data_for_nlp(train)\n",
    "dev_p = process_data_for_nlp(dev)\n",
    "\n",
    "train_p.shape, dev_p.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>is_goal</th>\n",
       "      <th>event_team_was_home</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Bafetimbi Gomis (Swansea City) wins a free kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Foul by Maya Yoshida (Southampton).</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Dusan Tadic (Southampton) wins a free kick on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Foul by Neil Taylor (Swansea City).</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Attempt saved. James Ward-Prowse (Southampton)...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp  time                                               text  \\\n",
       "0  004f4ING/  0.01  Bafetimbi Gomis (Swansea City) wins a free kic...   \n",
       "1  004f4ING/  0.01                Foul by Maya Yoshida (Southampton).   \n",
       "2  004f4ING/  0.05  Dusan Tadic (Southampton) wins a free kick on ...   \n",
       "3  004f4ING/  0.05                Foul by Neil Taylor (Swansea City).   \n",
       "4  004f4ING/  0.06  Attempt saved. James Ward-Prowse (Southampton)...   \n",
       "\n",
       "   is_goal  event_team_was_home  next_event_is_goal  \n",
       "0        0                    0                 0.0  \n",
       "1        0                    1                 0.0  \n",
       "2        0                    1                 0.0  \n",
       "3        0                    0                 0.0  \n",
       "4        0                    1                 0.0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>is_goal</th>\n",
       "      <th>event_team_was_home</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.03</td>\n",
       "      <td>Foul by Juan Manuel FalcA³n (Metz).</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TiemouA© Bakayoko (Monaco) wins a free kick in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Foul by Anthony Martial (Monaco).</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Sylvain Marchal (Metz) wins a free kick in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Foul by Cheick Doukoure (Metz).</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp  time                                               text  \\\n",
       "0  00nmICd9/  0.03                Foul by Juan Manuel FalcA³n (Metz).   \n",
       "1  00nmICd9/  0.03  TiemouA© Bakayoko (Monaco) wins a free kick in...   \n",
       "2  00nmICd9/  0.07                  Foul by Anthony Martial (Monaco).   \n",
       "3  00nmICd9/  0.07  Sylvain Marchal (Metz) wins a free kick in the...   \n",
       "4  00nmICd9/  0.07                    Foul by Cheick Doukoure (Metz).   \n",
       "\n",
       "   is_goal  event_team_was_home  next_event_is_goal  \n",
       "0        0                    1                 0.0  \n",
       "1        0                    0                 0.0  \n",
       "2        0                    0                 0.0  \n",
       "3        0                    1                 0.0  \n",
       "4        0                    1                 0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text commentary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe we are using is uncased so change all text to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_text_commentary(df):\n",
    "    df['text_lowercase'] = df['text'].str.lower()  # GloVe is lowercase\n",
    "    df['text_split'] = df['text_lowercase'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 37s, sys: 313 ms, total: 1min 37s\n",
      "Wall time: 1min 37s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenize_text_commentary(train_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.1 s, sys: 41.8 ms, total: 12.2 s\n",
      "Wall time: 12.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenize_text_commentary(dev_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>is_goal</th>\n",
       "      <th>event_team_was_home</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Bafetimbi Gomis (Swansea City) wins a free kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bafetimbi gomis (swansea city) wins a free kic...</td>\n",
       "      <td>[bafetimbi, gomis, (, swansea, city, ), wins, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Foul by Maya Yoshida (Southampton).</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by maya yoshida (southampton).</td>\n",
       "      <td>[foul, by, maya, yoshida, (, southampton, ), .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Dusan Tadic (Southampton) wins a free kick on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dusan tadic (southampton) wins a free kick on ...</td>\n",
       "      <td>[dusan, tadic, (, southampton, ), wins, a, fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Foul by Neil Taylor (Swansea City).</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by neil taylor (swansea city).</td>\n",
       "      <td>[foul, by, neil, taylor, (, swansea, city, ), .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Attempt saved. James Ward-Prowse (Southampton)...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attempt saved. james ward-prowse (southampton)...</td>\n",
       "      <td>[attempt, saved, ., james, ward-prowse, (, sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp  time                                               text  \\\n",
       "0  004f4ING/  0.01  Bafetimbi Gomis (Swansea City) wins a free kic...   \n",
       "1  004f4ING/  0.01                Foul by Maya Yoshida (Southampton).   \n",
       "2  004f4ING/  0.05  Dusan Tadic (Southampton) wins a free kick on ...   \n",
       "3  004f4ING/  0.05                Foul by Neil Taylor (Swansea City).   \n",
       "4  004f4ING/  0.06  Attempt saved. James Ward-Prowse (Southampton)...   \n",
       "\n",
       "   is_goal  event_team_was_home  next_event_is_goal  \\\n",
       "0        0                    0                 0.0   \n",
       "1        0                    1                 0.0   \n",
       "2        0                    1                 0.0   \n",
       "3        0                    0                 0.0   \n",
       "4        0                    1                 0.0   \n",
       "\n",
       "                                      text_lowercase  \\\n",
       "0  bafetimbi gomis (swansea city) wins a free kic...   \n",
       "1                foul by maya yoshida (southampton).   \n",
       "2  dusan tadic (southampton) wins a free kick on ...   \n",
       "3                foul by neil taylor (swansea city).   \n",
       "4  attempt saved. james ward-prowse (southampton)...   \n",
       "\n",
       "                                          text_split  \n",
       "0  [bafetimbi, gomis, (, swansea, city, ), wins, ...  \n",
       "1    [foul, by, maya, yoshida, (, southampton, ), .]  \n",
       "2  [dusan, tadic, (, southampton, ), wins, a, fre...  \n",
       "3   [foul, by, neil, taylor, (, swansea, city, ), .]  \n",
       "4  [attempt, saved, ., james, ward-prowse, (, sou...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>is_goal</th>\n",
       "      <th>event_team_was_home</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.03</td>\n",
       "      <td>Foul by Juan Manuel FalcA³n (Metz).</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by juan manuel falca³n (metz).</td>\n",
       "      <td>[foul, by, juan, manuel, falca³n, (, metz, ), .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.03</td>\n",
       "      <td>TiemouA© Bakayoko (Monaco) wins a free kick in...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>tiemoua© bakayoko (monaco) wins a free kick in...</td>\n",
       "      <td>[tiemoua©, bakayoko, (, monaco, ), wins, a, fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Foul by Anthony Martial (Monaco).</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by anthony martial (monaco).</td>\n",
       "      <td>[foul, by, anthony, martial, (, monaco, ), .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Sylvain Marchal (Metz) wins a free kick in the...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>sylvain marchal (metz) wins a free kick in the...</td>\n",
       "      <td>[sylvain, marchal, (, metz, ), wins, a, free, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>0.07</td>\n",
       "      <td>Foul by Cheick Doukoure (Metz).</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by cheick doukoure (metz).</td>\n",
       "      <td>[foul, by, cheick, doukoure, (, metz, ), .]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp  time                                               text  \\\n",
       "0  00nmICd9/  0.03                Foul by Juan Manuel FalcA³n (Metz).   \n",
       "1  00nmICd9/  0.03  TiemouA© Bakayoko (Monaco) wins a free kick in...   \n",
       "2  00nmICd9/  0.07                  Foul by Anthony Martial (Monaco).   \n",
       "3  00nmICd9/  0.07  Sylvain Marchal (Metz) wins a free kick in the...   \n",
       "4  00nmICd9/  0.07                    Foul by Cheick Doukoure (Metz).   \n",
       "\n",
       "   is_goal  event_team_was_home  next_event_is_goal  \\\n",
       "0        0                    1                 0.0   \n",
       "1        0                    0                 0.0   \n",
       "2        0                    0                 0.0   \n",
       "3        0                    1                 0.0   \n",
       "4        0                    1                 0.0   \n",
       "\n",
       "                                      text_lowercase  \\\n",
       "0                foul by juan manuel falca³n (metz).   \n",
       "1  tiemoua© bakayoko (monaco) wins a free kick in...   \n",
       "2                  foul by anthony martial (monaco).   \n",
       "3  sylvain marchal (metz) wins a free kick in the...   \n",
       "4                    foul by cheick doukoure (metz).   \n",
       "\n",
       "                                          text_split  \n",
       "0   [foul, by, juan, manuel, falca³n, (, metz, ), .]  \n",
       "1  [tiemoua©, bakayoko, (, monaco, ), wins, a, fr...  \n",
       "2      [foul, by, anthony, martial, (, monaco, ), .]  \n",
       "3  [sylvain, marchal, (, metz, ), wins, a, free, ...  \n",
       "4        [foul, by, cheick, doukoure, (, metz, ), .]  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all token lists together and find set to get vocab\n",
    "vocab_set = set(\n",
    "    itertools.chain.from_iterable(\n",
    "        list(train_p['text_split'])\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6468"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create token to index dict\n",
    "word_to_idx = dict(\n",
    "    zip(\n",
    "        vocab_set, \n",
    "        range(  # Start index from 1 as we reserve the 0 index for the padding vector\n",
    "            1,\n",
    "            len(vocab_set)+1\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.35 s, sys: 49 ms, total: 2.4 s\n",
      "Wall time: 2.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# For each sentence in training map tokens to corresponding index\n",
    "train_p['token_sequence'] = [[word_to_idx[token] for token in commentary] for commentary in list(train_p['text_split'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>is_goal</th>\n",
       "      <th>event_team_was_home</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>text_split</th>\n",
       "      <th>token_sequence</th>\n",
       "      <th>token_sequence_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Bafetimbi Gomis (Swansea City) wins a free kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bafetimbi gomis (swansea city) wins a free kic...</td>\n",
       "      <td>[bafetimbi, gomis, (, swansea, city, ), wins, ...</td>\n",
       "      <td>[2210, 4002, 5093, 4494, 1414, 1937, 711, 3426...</td>\n",
       "      <td>[2210, 4002, 5093, 4494, 1414, 1937, 711, 3426...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.01</td>\n",
       "      <td>Foul by Maya Yoshida (Southampton).</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by maya yoshida (southampton).</td>\n",
       "      <td>[foul, by, maya, yoshida, (, southampton, ), .]</td>\n",
       "      <td>[6156, 4936, 5146, 2985, 5093, 364, 1937, 5314]</td>\n",
       "      <td>[6156, 4936, 5146, 2985, 5093, 364, 1937, 5314...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Dusan Tadic (Southampton) wins a free kick on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dusan tadic (southampton) wins a free kick on ...</td>\n",
       "      <td>[dusan, tadic, (, southampton, ), wins, a, fre...</td>\n",
       "      <td>[1966, 2555, 5093, 364, 1937, 711, 3426, 6440,...</td>\n",
       "      <td>[1966, 2555, 5093, 364, 1937, 711, 3426, 6440,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.05</td>\n",
       "      <td>Foul by Neil Taylor (Swansea City).</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by neil taylor (swansea city).</td>\n",
       "      <td>[foul, by, neil, taylor, (, swansea, city, ), .]</td>\n",
       "      <td>[6156, 4936, 3743, 3231, 5093, 4494, 1414, 193...</td>\n",
       "      <td>[6156, 4936, 3743, 3231, 5093, 4494, 1414, 193...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.06</td>\n",
       "      <td>Attempt saved. James Ward-Prowse (Southampton)...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attempt saved. james ward-prowse (southampton)...</td>\n",
       "      <td>[attempt, saved, ., james, ward-prowse, (, sou...</td>\n",
       "      <td>[4453, 670, 5314, 3262, 2348, 5093, 364, 1937,...</td>\n",
       "      <td>[4453, 670, 5314, 3262, 2348, 5093, 364, 1937,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp  time                                               text  \\\n",
       "0  004f4ING/  0.01  Bafetimbi Gomis (Swansea City) wins a free kic...   \n",
       "1  004f4ING/  0.01                Foul by Maya Yoshida (Southampton).   \n",
       "2  004f4ING/  0.05  Dusan Tadic (Southampton) wins a free kick on ...   \n",
       "3  004f4ING/  0.05                Foul by Neil Taylor (Swansea City).   \n",
       "4  004f4ING/  0.06  Attempt saved. James Ward-Prowse (Southampton)...   \n",
       "\n",
       "   is_goal  event_team_was_home  next_event_is_goal  \\\n",
       "0        0                    0                 0.0   \n",
       "1        0                    1                 0.0   \n",
       "2        0                    1                 0.0   \n",
       "3        0                    0                 0.0   \n",
       "4        0                    1                 0.0   \n",
       "\n",
       "                                      text_lowercase  \\\n",
       "0  bafetimbi gomis (swansea city) wins a free kic...   \n",
       "1                foul by maya yoshida (southampton).   \n",
       "2  dusan tadic (southampton) wins a free kick on ...   \n",
       "3                foul by neil taylor (swansea city).   \n",
       "4  attempt saved. james ward-prowse (southampton)...   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  [bafetimbi, gomis, (, swansea, city, ), wins, ...   \n",
       "1    [foul, by, maya, yoshida, (, southampton, ), .]   \n",
       "2  [dusan, tadic, (, southampton, ), wins, a, fre...   \n",
       "3   [foul, by, neil, taylor, (, swansea, city, ), .]   \n",
       "4  [attempt, saved, ., james, ward-prowse, (, sou...   \n",
       "\n",
       "                                      token_sequence  \\\n",
       "0  [2210, 4002, 5093, 4494, 1414, 1937, 711, 3426...   \n",
       "1    [6156, 4936, 5146, 2985, 5093, 364, 1937, 5314]   \n",
       "2  [1966, 2555, 5093, 364, 1937, 711, 3426, 6440,...   \n",
       "3  [6156, 4936, 3743, 3231, 5093, 4494, 1414, 193...   \n",
       "4  [4453, 670, 5314, 3262, 2348, 5093, 364, 1937,...   \n",
       "\n",
       "                                    token_sequence_1  \n",
       "0  [2210, 4002, 5093, 4494, 1414, 1937, 711, 3426...  \n",
       "1  [6156, 4936, 5146, 2985, 5093, 364, 1937, 5314...  \n",
       "2  [1966, 2555, 5093, 364, 1937, 711, 3426, 6440,...  \n",
       "3  [6156, 4936, 3743, 3231, 5093, 4494, 1414, 193...  \n",
       "4  [4453, 670, 5314, 3262, 2348, 5093, 364, 1937,...  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_LENGTH = np.max([len(seq) for seq in train_p['token_sequence']])  # Max length of tokens for any sentence in the training data\n",
    "MAX_LENGTH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence(sentence_seq, max_length=MAX_LENGTH):\n",
    "    \"\"\"\n",
    "    Takes a list of numbers representing a sentence and appends zeros to the list until `max_length` is achieved.\n",
    "    \"\"\"\n",
    "    if len(sentence_seq) < max_length:\n",
    "        num_zeros_to_add = max_length - len(sentence_seq)\n",
    "        zeros_list = list(np.zeros(num_zeros_to_add))\n",
    "        zeros_list = [int(x) for x in zeros_list]  # Convert zeros to int\n",
    "        \n",
    "        sentence_seq = sentence_seq + zeros_list\n",
    "        \n",
    "    return sentence_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentaryDataset(Dataset):\n",
    "\n",
    "    def __init__(self, data, word_to_idx, max_length=MAX_LENGTH):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        data = data.copy()\n",
    "        \n",
    "        # Initial pre-processing\n",
    "        data = process_data_for_nlp(data)\n",
    "        \n",
    "        # Tokenise text commentary\n",
    "        tokenize_text_commentary(data)\n",
    "        \n",
    "        # Look up each token in word_to_index (from training) and get index value or drop if not in dictionary\n",
    "        data['token_sequence'] = [\n",
    "            [word_to_idx.get(token) for token in commentary if word_to_idx.get(token) != None] for commentary in list(data['text_split'])\n",
    "        ]\n",
    "        \n",
    "        # Trim to length\n",
    "        data['token_sequence'] = [token_sequence[:max_length] for token_sequence in list(data['token_sequence'])]\n",
    "        \n",
    "        # Pad sentences\n",
    "        data['token_sequence'] = [pad_sentence(token_sequence) for token_sequence in data['token_sequence']]\n",
    "        \n",
    "        # Lagged features\n",
    "        for i in range(1,5):\n",
    "            data[f'token_sequence_minus_{i}'] = data.groupby('id_odsp')['token_sequence'].shift(i)\n",
    "            data[f'time_minus_{i}'] = data.groupby('id_odsp')['time'].shift(i)\n",
    "            data[f'is_goal_minus_{i}'] = data.groupby('id_odsp')['is_goal'].shift(i)\n",
    "            \n",
    "        data.dropna(axis=0, how='any', inplace=True)  # Drop rows with empty features caused by lag\n",
    "        \n",
    "        token_sequence = ['token_sequence'] + [f'token_sequence_minus_{i}' for i in range(1, 5)]\n",
    "        token_sequence.reverse()  # Order from furthest away to most recent\n",
    "        self.token_sequence = np.array(data[token_sequence].values.tolist())  # Create 3D matrix of token sequences of shape (batch size, timesteps, tokens)\n",
    "        \n",
    "        time = ['time'] + [f'time_minus_{i}' for i in range(1, 5)]\n",
    "        time.reverse()\n",
    "        self.time = data[time].values\n",
    "        \n",
    "        goal = ['is_goal'] + [f'is_goal_minus_{i}' for i in range(1, 5)]\n",
    "        goal.reverse()\n",
    "        self.goal = data[goal].values\n",
    "        \n",
    "        self.event_team_was_home = data['event_team_was_home'].values\n",
    "        \n",
    "        self.y = data['next_event_is_goal'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.token_sequence.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        return self.token_sequence[idx, :, :], self.time[idx, :], self.goal[idx, :], self.event_team_was_home[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 6s, sys: 1.39 s, total: 2min 7s\n",
      "Wall time: 2min 7s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_comm = CommentaryDataset(train, word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.9 s, sys: 145 ms, total: 15 s\n",
      "Wall time: 15.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dev_comm = CommentaryDataset(dev, word_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create training array where each row has the token indices for the word in that sentence\n",
    "# X_train = np.array(\n",
    "#     list(train_p['token_sequence'])\n",
    "# )\n",
    "\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.82 s, sys: 212 ms, total: 7.03 s\n",
      "Wall time: 7.04 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_to_vector = {}\n",
    "with open('data/external/glove.6B.100d.txt', \"r\") as f:\n",
    "    # Each line starts with the word/character followed by the 100d vector representation\n",
    "    for line in f:\n",
    "        \n",
    "        # Split by whitespace:\n",
    "        components = line.split()\n",
    "        \n",
    "        word = components[0]\n",
    "        vector_values = components[1:]\n",
    "        \n",
    "        vector_array = np.array(vector_values, dtype=np.float64)  # Convert vector to numpy array\n",
    "        \n",
    "        # Add to dictionary\n",
    "        word_to_vector[word] = vector_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_vector.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.8509e-01, -8.0413e-01,  7.3326e-01, -1.1997e+00, -4.4433e-01,\n",
       "        9.9010e-01, -1.1211e-01, -7.0893e-01, -1.4639e-01, -1.9667e-01,\n",
       "       -1.4831e-01, -1.0859e-01, -3.9821e-01, -4.9383e-01,  1.0474e+00,\n",
       "        6.4321e-01, -6.4378e-01, -2.7974e-01, -4.2865e-01,  5.5361e-02,\n",
       "        2.1271e-01,  6.2063e-01,  1.1255e-01, -9.9549e-02,  5.2189e-01,\n",
       "       -2.9921e-01, -6.3453e-01,  5.5675e-01,  1.0460e-01, -1.0456e-01,\n",
       "        3.0833e-02, -1.0498e-03,  5.6656e-01, -1.1333e-01, -5.8664e-02,\n",
       "       -5.9103e-01, -2.2791e-01,  3.2208e-01,  6.9484e-02,  3.6374e-01,\n",
       "       -3.4399e-01,  3.3388e-02,  1.2079e-01, -6.0931e-01, -3.2988e-01,\n",
       "        5.1176e-02, -3.5307e-01, -4.5887e-02, -2.0085e-01, -6.6991e-01,\n",
       "        4.3831e-01,  3.8817e-01, -9.4224e-01,  5.2481e-01, -7.7710e-02,\n",
       "       -1.3177e+00, -1.2479e-01,  3.3277e-01,  1.1003e+00,  4.8362e-01,\n",
       "       -3.4234e-01,  1.5704e-01, -6.7879e-01,  4.4289e-01, -1.7270e-01,\n",
       "       -5.3625e-01,  1.0005e+00, -9.6411e-01, -1.2487e+00, -1.9425e-01,\n",
       "       -1.0907e+00,  1.6932e-01,  7.1101e-01, -3.1025e-02,  1.8118e-01,\n",
       "        3.9567e-01, -3.1815e-01, -2.0455e-01, -1.4048e-02,  9.9726e-01,\n",
       "        5.4227e-01,  2.6200e-01, -9.6486e-01,  6.7644e-02, -1.3214e+00,\n",
       "       -7.1359e-01,  3.2818e-01,  3.5588e-01,  3.8178e-01, -1.1369e-01,\n",
       "       -7.3429e-01, -8.9334e-02, -1.1049e+00,  2.7504e-01,  3.8443e-01,\n",
       "        1.5828e-01, -6.0444e-01,  2.5557e-01, -3.4384e-01, -4.8057e-01])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_vector['foul']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIMENSION = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6469, 100)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create empty matrix for embedding matrix\n",
    "embedding_matrix = np.zeros(\n",
    "    (\n",
    "        len(vocab_set) + 1,  # Additional 1 for zero vector for padding\n",
    "        GLOVE_DIMENSION\n",
    "    )\n",
    ")\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6468"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_to_idx.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "for word, idx in word_to_idx.items():\n",
    "    try:\n",
    "        embedding_matrix[idx, :] = word_to_vector[word]\n",
    "    except KeyError:  # Word in training set not in GloVe\n",
    "        embedding_matrix[idx, :] = np.zeros(GLOVE_DIMENSION)  # We replace unknown words with zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.      ,  0.      ,  0.      , ...,  0.      ,  0.      ,\n",
       "         0.      ],\n",
       "       [ 0.54137 , -0.28764 , -0.73927 , ..., -0.18333 , -0.36724 ,\n",
       "        -0.93653 ],\n",
       "       [-0.71766 ,  0.80871 ,  0.31868 , ..., -1.0023  ,  0.8588  ,\n",
       "         0.28583 ],\n",
       "       ...,\n",
       "       [-0.14006 , -0.23714 , -0.17842 , ..., -0.47708 ,  0.16928 ,\n",
       "        -0.26209 ],\n",
       "       [ 0.048094, -0.48372 , -0.1568  , ...,  0.65844 , -0.55271 ,\n",
       "         0.10198 ],\n",
       "       [ 0.043713, -0.31769 , -0.44245 , ...,  0.17994 , -0.78125 ,\n",
       "         0.20462 ]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1885"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(embedding_matrix.sum(axis=1) == 0)  # Number of words in vocab but not in GloVe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensor for PyTorch\n",
    "embedding_tensor = torch.from_numpy(embedding_matrix)\n",
    "embedding_tensor = embedding_tensor.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713655, 50)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comm.token_sequence[:,1,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713655,)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comm.event_team_was_home.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713655, 5)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comm.goal.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713655, 5)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comm.time.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713655,)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comm.y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(713655, 2)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate((train_comm.event_team_was_home.reshape(-1,1), train_comm.event_team_was_home.reshape(-1,1)), axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('int64')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comm.token_sequence[:,0,:][0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
       "        [ 0.5414, -0.2876, -0.7393,  ..., -0.1833, -0.3672, -0.9365],\n",
       "        [-0.7177,  0.8087,  0.3187,  ..., -1.0023,  0.8588,  0.2858],\n",
       "        ...,\n",
       "        [-0.1401, -0.2371, -0.1784,  ..., -0.4771,  0.1693, -0.2621],\n",
       "        [ 0.0481, -0.4837, -0.1568,  ...,  0.6584, -0.5527,  0.1020],\n",
       "        [ 0.0437, -0.3177, -0.4425,  ...,  0.1799, -0.7812,  0.2046]],\n",
       "       device='cuda:0', dtype=torch.float64)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextEventIsGoal(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NextEventIsGoal, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings=embedding_tensor, freeze=False)\n",
    "        # LSTM\n",
    "        self.lstm_sentences = nn.LSTM(input_size=GLOVE_DIMENSION, hidden_size=125, batch_first=True)\n",
    "        self.lstm_features = nn.LSTM(input_size=125+2, hidden_size=300, batch_first=True)\n",
    "        \n",
    "        # MLP\n",
    "        self.fc_1 = nn.Linear(in_features=300+1, out_features=125)\n",
    "        self.fc_2 = nn.Linear(in_features=125, out_features=1)\n",
    "\n",
    "        xavier_uniform_(self.fc_1.weight)  # in-place\n",
    "        xavier_uniform_(self.fc_2.weight)  # in-place        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, token_sequence, event_team_was_home, goal, time):\n",
    "        \n",
    "        x_0 = self.embedding(token_sequence[:,0,:])\n",
    "        x_0 = x_0.float()\n",
    "        all_h_t0, _ = self.lstm_sentences(x_0)\n",
    "        h_T0 = all_h_t0[:, -1, :]  # Final cell outputs\n",
    "        \n",
    "        x_1 = self.embedding(token_sequence[:,1,:])\n",
    "        x_1 = x_1.float()\n",
    "        all_h_t1, _ = self.lstm_sentences(x_1)\n",
    "        h_T1 = all_h_t1[:, -1, :]  # Final cell outputs\n",
    "        \n",
    "        x_2 = self.embedding(token_sequence[:,2,:])\n",
    "        x_2 = x_2.float()\n",
    "        all_h_t2, _ = self.lstm_sentences(x_2)\n",
    "        h_T2 = all_h_t2[:, -1, :]  # Final cell outputs\n",
    "        \n",
    "        x_3 = self.embedding(token_sequence[:,3,:])\n",
    "        x_3 = x_3.float()\n",
    "        all_h_t3, _ = self.lstm_sentences(x_3)\n",
    "        h_T3 = all_h_t3[:, -1, :]  # Final cell outputs\n",
    "        \n",
    "        x_4 = self.embedding(token_sequence[:,4,:])\n",
    "        x_4 = x_4.float()\n",
    "        all_h_t4, _ = self.lstm_sentences(x_4)\n",
    "        h_T4 = all_h_t4[:, -1, :]  # Final cell outputs\n",
    "        \n",
    "        sentence_representation_over_time = torch.stack(\n",
    "            (h_T0, h_T1, h_T2, h_T3, h_T4),\n",
    "            dim=1  # Put timesteps on axis 1\n",
    "        )\n",
    "        \n",
    "        goal_and_mins_over_time = torch.stack(\n",
    "            (goal, time),\n",
    "            dim=2  # Feautures as 3rd dimension\n",
    "        )\n",
    "        \n",
    "        x = torch.cat(\n",
    "            (sentence_representation_over_time, goal_and_mins_over_time), \n",
    "            dim=2\n",
    "        )\n",
    "        \n",
    "        x = x.float()\n",
    "        \n",
    "        all_h_t, _ = self.lstm_features(x)\n",
    "        h_T = all_h_t[:, -1, :]  # Final cell outputs\n",
    "        \n",
    "        x = torch.cat((h_T, event_team_was_home.reshape(-1, 1)), dim=1)\n",
    "        \n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextEventIsGoal(\n",
       "  (embedding): Embedding(6469, 100)\n",
       "  (lstm_sentences): LSTM(100, 125, batch_first=True)\n",
       "  (lstm_features): LSTM(127, 300, batch_first=True)\n",
       "  (fc_1): Linear(in_features=301, out_features=125, bias=True)\n",
       "  (fc_2): Linear(in_features=125, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NextEventIsGoal()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of NextEventIsGoal(\n",
       "  (embedding): Embedding(6469, 100)\n",
       "  (lstm_sentences): LSTM(100, 125, batch_first=True)\n",
       "  (lstm_features): LSTM(127, 300, batch_first=True)\n",
       "  (fc_1): Linear(in_features=301, out_features=125, bias=True)\n",
       "  (fc_2): Linear(in_features=125, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1313076"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimiser = optim.Adam(params=model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use subset of training data otherwise takes forever..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "713655"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_comm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_subset_examples = 1000\n",
    "\n",
    "train_ncd_subset = torch.utils.data.Subset(\n",
    "    train_comm, \n",
    "    indices=np.random.choice(\n",
    "        range(len(train_comm)), \n",
    "        num_subset_examples\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "dev_losses = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62.5"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1000/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n",
      "  0%|          | 0/125 [00:00<?, ?it/s]\u001b[A\n",
      "  3%|▎         | 4/125 [00:00<00:03, 31.03it/s]\u001b[A\n",
      "  6%|▌         | 7/125 [00:00<00:03, 30.45it/s]\u001b[A\n",
      "  8%|▊         | 10/125 [00:00<00:03, 30.16it/s]\u001b[A\n",
      " 10%|█         | 13/125 [00:00<00:03, 30.05it/s]\u001b[A\n",
      " 13%|█▎        | 16/125 [00:00<00:03, 30.01it/s]\u001b[A\n",
      " 15%|█▌        | 19/125 [00:00<00:03, 29.98it/s]\u001b[A\n",
      " 18%|█▊        | 22/125 [00:00<00:03, 29.91it/s]\u001b[A\n",
      " 20%|██        | 25/125 [00:00<00:03, 29.83it/s]\u001b[A\n",
      " 22%|██▏       | 28/125 [00:00<00:03, 29.73it/s]\u001b[A\n",
      " 26%|██▌       | 32/125 [00:01<00:03, 30.04it/s]\u001b[A\n",
      " 29%|██▉       | 36/125 [00:01<00:02, 30.22it/s]\u001b[A\n",
      " 31%|███       | 39/125 [00:01<00:02, 30.01it/s]\u001b[A\n",
      " 34%|███▍      | 43/125 [00:01<00:02, 30.20it/s]\u001b[A\n",
      " 38%|███▊      | 47/125 [00:01<00:02, 30.36it/s]\u001b[A\n",
      " 41%|████      | 51/125 [00:01<00:02, 30.34it/s]\u001b[A\n",
      " 44%|████▍     | 55/125 [00:01<00:02, 30.46it/s]\u001b[A\n",
      " 47%|████▋     | 59/125 [00:01<00:02, 30.35it/s]\u001b[A\n",
      " 50%|█████     | 63/125 [00:02<00:02, 30.52it/s]\u001b[A\n",
      " 54%|█████▎    | 67/125 [00:02<00:01, 30.55it/s]\u001b[A\n",
      " 57%|█████▋    | 71/125 [00:02<00:01, 30.50it/s]\u001b[A\n",
      " 60%|██████    | 75/125 [00:02<00:01, 30.48it/s]\u001b[A\n",
      " 63%|██████▎   | 79/125 [00:02<00:01, 30.49it/s]\u001b[A\n",
      " 66%|██████▋   | 83/125 [00:02<00:01, 30.63it/s]\u001b[A\n",
      " 70%|██████▉   | 87/125 [00:02<00:01, 30.58it/s]\u001b[A\n",
      " 73%|███████▎  | 91/125 [00:03<00:01, 30.59it/s]\u001b[A\n",
      " 76%|███████▌  | 95/125 [00:03<00:00, 30.55it/s]\u001b[A\n",
      " 79%|███████▉  | 99/125 [00:03<00:00, 30.61it/s]\u001b[A\n",
      " 82%|████████▏ | 103/125 [00:03<00:00, 30.54it/s]\u001b[A\n",
      " 86%|████████▌ | 107/125 [00:03<00:00, 30.57it/s]\u001b[A\n",
      " 89%|████████▉ | 111/125 [00:03<00:00, 30.61it/s]\u001b[A\n",
      " 92%|█████████▏| 115/125 [00:03<00:00, 30.56it/s]\u001b[A\n",
      " 95%|█████████▌| 119/125 [00:03<00:00, 30.54it/s]\u001b[A\n",
      "100%|██████████| 125/125 [00:04<00:00, 30.36it/s]\u001b[A\n",
      "  0%|          | 0/10 [00:04<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 1.93 GiB total capacity; 1.02 GiB already allocated; 28.75 MiB free; 1.21 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/Github/football-commentary/env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-228-a492a791db79>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, token_sequence, event_team_was_home, goal, time)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken_sequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mx_0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mall_h_t0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mh_T0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_h_t0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Final cell outputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/football-commentary/env/lib64/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/football-commentary/env/lib64/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 582\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    583\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 120.00 MiB (GPU 0; 1.93 GiB total capacity; 1.02 GiB already allocated; 28.75 MiB free; 1.21 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in tqdm(range(10), position=0):\n",
    "    for data in tqdm(DataLoader(train_ncd_subset, batch_size=8), position=1):\n",
    "        \n",
    "        token_sequence, time, goal, event_team_was_home, y = data\n",
    "        token_sequence, time, goal, event_team_was_home, y = token_sequence.to(device), time.to(device), goal.to(device), event_team_was_home.to(device), y.reshape(-1,1).to(device)\n",
    "\n",
    "        optimiser.zero_grad()  # Set gradients to 0 otherwise will accumulate\n",
    "\n",
    "        y_pred = model(token_sequence, event_team_was_home, goal, time)\n",
    "        loss = criterion(y_pred, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    \n",
    "    # Training loss\n",
    "    training_loss_total = 0\n",
    "    for data in DataLoader(train_ncd_subset, batch_size=2048, shuffle=True):\n",
    "        token_sequence, time, goal, event_team_was_home, y = data\n",
    "        token_sequence, time, goal, event_team_was_home, y = token_sequence.to(device), time.to(device), goal.to(device), event_team_was_home.to(device), y.reshape(-1,1).to(device)\n",
    "        \n",
    "        y_pred = model(token_sequence, event_team_was_home, goal, time)\n",
    "        \n",
    "        batch_loss_sum = float(\n",
    "            nn.BCELoss(reduction='sum')(y_pred, y.float())\n",
    "        )\n",
    "        training_loss_total += batch_loss_sum\n",
    "    \n",
    "    loss = training_loss_total / len(train_ncd_subset)\n",
    "    training_losses.append(loss)\n",
    "        \n",
    "    # Dev loss\n",
    "#     dev_loss_total = 0\n",
    "#     for data in DataLoader(commentary_dev, batch_size=2048):\n",
    "#         X_dev, y_dev = data\n",
    "#         X_dev, y_dev = X_dev.to(device), y_dev.to(device)\n",
    "        \n",
    "#         y_pred = model(X_dev)\n",
    "        \n",
    "#         batch_loss_sum = float(\n",
    "#             nn.BCELoss(reduction='sum')(y_pred, y_dev.float())\n",
    "#         )\n",
    "#         dev_loss_total += batch_loss_sum\n",
    "        \n",
    "#     loss = dev_loss_total / len(commentary_dev)\n",
    "#     dev_losses.append(loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, train_loss: {training_losses[-1]}, dev_loss: {dev_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "arrays must all be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-246-7e2172ad2a10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtraining_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'dev'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdev_losses\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/football-commentary/env/lib64/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 468\u001b[0;31m             \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minit_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    469\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaskedArray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmrecords\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmrecords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/football-commentary/env/lib64/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36minit_dict\u001b[0;34m(data, index, columns, dtype)\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0marr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_datetime64tz_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         ]\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays_to_mgr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/football-commentary/env/lib64/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, arr_names, index, columns, dtype, verify_integrity)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;31m# figure out the index, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Github/football-commentary/env/lib64/python3.6/site-packages/pandas/core/internals/construction.py\u001b[0m in \u001b[0;36mextract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    395\u001b[0m             \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_lengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    396\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 397\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"arrays must all be same length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhave_dicts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: arrays must all be same length"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "pd.DataFrame({'train': training_losses, 'dev': dev_losses}).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for data in DataLoader(commentary_train, batch_size=2048):\n",
    "    X_train, y_train = data\n",
    "    X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "\n",
    "    y_pred = model(X_train)\n",
    "    \n",
    "    y_train_list.append(y_train.detach().cpu().numpy())\n",
    "    y_pred_list.append(y_pred.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_pred = np.concatenate(y_pred_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6724677853670019"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for data in DataLoader(commentary_dev, batch_size=256):\n",
    "    X_dev, y_dev = data\n",
    "    X_dev, y_dev = X_dev.to(device), y_dev.to(device)\n",
    "\n",
    "    y_pred = model(X_dev)\n",
    "    \n",
    "    y_dev_list.append(y_dev.detach().cpu().numpy())\n",
    "    y_pred_list.append(y_pred.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = np.concatenate(y_dev_list, axis=0)\n",
    "y_pred = np.concatenate(y_pred_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6503720392454373"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add minutes and home team features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create custom Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((742443, 50), (742443,), (91789, 50), (91789,))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_dev.shape, y_dev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>event_team_was_home</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>text_split</th>\n",
       "      <th>token_sequence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>Bafetimbi Gomis (Swansea City) wins a free kic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bafetimbi gomis (swansea city) wins a free kic...</td>\n",
       "      <td>[bafetimbi, gomis, (, swansea, city, ), wins, ...</td>\n",
       "      <td>[5455, 3019, 2529, 4858, 52, 3767, 4304, 3725,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.010101</td>\n",
       "      <td>Foul by Maya Yoshida (Southampton).</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by maya yoshida (southampton).</td>\n",
       "      <td>[foul, by, maya, yoshida, (, southampton, ), .]</td>\n",
       "      <td>[5791, 4039, 1961, 3289, 2529, 3338, 3767, 560...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>Dusan Tadic (Southampton) wins a free kick on ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dusan tadic (southampton) wins a free kick on ...</td>\n",
       "      <td>[dusan, tadic, (, southampton, ), wins, a, fre...</td>\n",
       "      <td>[5731, 5113, 2529, 3338, 3767, 4304, 3725, 324...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.050505</td>\n",
       "      <td>Foul by Neil Taylor (Swansea City).</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by neil taylor (swansea city).</td>\n",
       "      <td>[foul, by, neil, taylor, (, swansea, city, ), .]</td>\n",
       "      <td>[5791, 4039, 2798, 1976, 2529, 4858, 52, 3767,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>Attempt saved. James Ward-Prowse (Southampton)...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attempt saved. james ward-prowse (southampton)...</td>\n",
       "      <td>[attempt, saved, ., james, ward-prowse, (, sou...</td>\n",
       "      <td>[5043, 1098, 5600, 165, 5305, 2529, 3338, 3767...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp      time                                               text  \\\n",
       "0  004f4ING/  0.010101  Bafetimbi Gomis (Swansea City) wins a free kic...   \n",
       "1  004f4ING/  0.010101                Foul by Maya Yoshida (Southampton).   \n",
       "2  004f4ING/  0.050505  Dusan Tadic (Southampton) wins a free kick on ...   \n",
       "3  004f4ING/  0.050505                Foul by Neil Taylor (Swansea City).   \n",
       "4  004f4ING/  0.060606  Attempt saved. James Ward-Prowse (Southampton)...   \n",
       "\n",
       "   event_team_was_home  next_event_is_goal  \\\n",
       "0                    0                 0.0   \n",
       "1                    1                 0.0   \n",
       "2                    1                 0.0   \n",
       "3                    0                 0.0   \n",
       "4                    1                 0.0   \n",
       "\n",
       "                                      text_lowercase  \\\n",
       "0  bafetimbi gomis (swansea city) wins a free kic...   \n",
       "1                foul by maya yoshida (southampton).   \n",
       "2  dusan tadic (southampton) wins a free kick on ...   \n",
       "3                foul by neil taylor (swansea city).   \n",
       "4  attempt saved. james ward-prowse (southampton)...   \n",
       "\n",
       "                                          text_split  \\\n",
       "0  [bafetimbi, gomis, (, swansea, city, ), wins, ...   \n",
       "1    [foul, by, maya, yoshida, (, southampton, ), .]   \n",
       "2  [dusan, tadic, (, southampton, ), wins, a, fre...   \n",
       "3   [foul, by, neil, taylor, (, swansea, city, ), .]   \n",
       "4  [attempt, saved, ., james, ward-prowse, (, sou...   \n",
       "\n",
       "                                      token_sequence  \n",
       "0  [5455, 3019, 2529, 4858, 52, 3767, 4304, 3725,...  \n",
       "1  [5791, 4039, 1961, 3289, 2529, 3338, 3767, 560...  \n",
       "2  [5731, 5113, 2529, 3338, 3767, 4304, 3725, 324...  \n",
       "3  [5791, 4039, 2798, 1976, 2529, 4858, 52, 3767,...  \n",
       "4  [5043, 1098, 5600, 165, 5305, 2529, 3338, 3767...  "
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scalar = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p['time'] = min_max_scalar.fit_transform(train_p[['time']]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_p['time'] = min_max_scalar.transform(dev_p[['time']]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_home_train = train_p.copy()[['time', 'event_team_was_home']].values\n",
    "time_home_dev = dev_p.copy()[['time', 'event_team_was_home']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentaryDatasetPlus(Dataset):\n",
    "\n",
    "    def __init__(self, X, y, time_home_features):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y.reshape(-1, 1)\n",
    "        self.time_home_features = time_home_features\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        return self.X[idx, :], self.time_home_features[idx, :], self.y[idx, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentary_train_plus = CommentaryDatasetPlus(X_train, y_train, time_home_train)\n",
    "commentary_dev_plus = CommentaryDatasetPlus(X_dev, y_dev, time_home_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NextEventIsGoalPlus(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(NextEventIsGoalPlus, self).__init__()\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding.from_pretrained(embeddings=embedding_tensor, freeze=False)\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=GLOVE_DIMENSION, hidden_size=125, batch_first=True)\n",
    "        # MLP\n",
    "        self.fc_1 = nn.Linear(in_features=125+2, out_features=125)  # +2 for time and home features\n",
    "        self.fc_2 = nn.Linear(in_features=125, out_features=1)\n",
    "\n",
    "        xavier_uniform_(self.fc_1.weight)  # in-place\n",
    "        xavier_uniform_(self.fc_2.weight)  # in-place        \n",
    "        \n",
    "        self.dropout = nn.Dropout(p=0)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x, x_time_home):\n",
    "        x = self.embedding(x)\n",
    "        \n",
    "        x = x.float()\n",
    "        x_time_home = x_time_home.float()\n",
    "        \n",
    "        all_h_t, _ = self.lstm(x)\n",
    "        \n",
    "        h_T = all_h_t[:, -1, :]  # Final cell outputs\n",
    "        \n",
    "        x = torch.cat((h_T, x_time_home), dim=1)\n",
    "        \n",
    "        x = self.fc_1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc_2(x)\n",
    "\n",
    "        x = self.sigmoid(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NextEventIsGoalPlus(\n",
       "  (embedding): Embedding(6469, 100)\n",
       "  (lstm): LSTM(100, 125, batch_first=True)\n",
       "  (fc_1): Linear(in_features=127, out_features=125, bias=True)\n",
       "  (fc_2): Linear(in_features=125, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NextEventIsGoalPlus()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Module.named_parameters of NextEventIsGoalPlus(\n",
       "  (embedding): Embedding(6469, 100)\n",
       "  (lstm): LSTM(100, 125, batch_first=True)\n",
       "  (fc_1): Linear(in_features=127, out_features=125, bias=True)\n",
       "  (fc_2): Linear(in_features=125, out_features=1, bias=True)\n",
       "  (dropout): Dropout(p=0, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (sigmoid): Sigmoid()\n",
       ")>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.named_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "776526"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/49201236/check-the-total-number-of-parameters-in-a-pytorch-model\n",
    "sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.BCELoss()\n",
    "optimiser = optim.Adam(params=model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use subset of training data otherwise takes forever..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742443"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(commentary_train_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_subset_examples = 50000\n",
    "\n",
    "# train_ncd_subset = torch.utils.data.Subset(\n",
    "#     commentary_train_plus, \n",
    "#     indices=np.random.choice(\n",
    "#         range(len(commentary_train_plus)), \n",
    "#         num_subset_examples\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_losses = []\n",
    "dev_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, train_loss: 0.11283278551108274, dev_loss: 0.1192946303160784\n",
      "Epoch: 2, train_loss: 0.11269831692717594, dev_loss: 0.11941011535204334\n",
      "Epoch: 3, train_loss: 0.11257904717308226, dev_loss: 0.11954914900267681\n",
      "Epoch: 4, train_loss: 0.11249491840436912, dev_loss: 0.1198080030532985\n",
      "Epoch: 5, train_loss: 0.1124026030508974, dev_loss: 0.12012534370169266\n",
      "CPU times: user 13min 20s, sys: 4min 7s, total: 17min 28s\n",
      "Wall time: 17min 28s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# training_losses = []\n",
    "# dev_losses = []\n",
    "\n",
    "for epoch in range(5):\n",
    "    for data in DataLoader(commentary_train_plus, batch_size=256):\n",
    "        \n",
    "        X, X_time_home, y = data\n",
    "        X, X_time_home, y = X.to(device), X_time_home.to(device), y.to(device)\n",
    "\n",
    "        optimiser.zero_grad()  # Set gradients to 0 otherwise will accumulate\n",
    "\n",
    "        y_pred = model(X, X_time_home)\n",
    "        loss = criterion(y_pred, y.float())\n",
    "\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "    \n",
    "    # Training loss\n",
    "    training_loss_total = 0\n",
    "    for data in DataLoader(commentary_train_plus, batch_size=256, shuffle=True):\n",
    "        X_train, X_time_home_train, y_train = data\n",
    "        X_train, X_time_home_train, y_train = X_train.to(device), X_time_home_train.to(device), y_train.to(device)\n",
    "        \n",
    "        y_pred = model(X_train, X_time_home_train)\n",
    "        \n",
    "        batch_loss_sum = float(\n",
    "            nn.BCELoss(reduction='sum')(y_pred, y_train.float())\n",
    "        )\n",
    "        training_loss_total += batch_loss_sum\n",
    "    \n",
    "    loss = training_loss_total / len(commentary_train_plus)\n",
    "    training_losses.append(loss)\n",
    "        \n",
    "    # Dev loss\n",
    "    dev_loss_total = 0\n",
    "    for data in DataLoader(commentary_dev_plus, batch_size=256):\n",
    "        X_dev, X_time_home_dev, y_dev = data\n",
    "        X_dev, X_time_home_dev, y_dev = X_dev.to(device), X_time_home_dev.to(device), y_dev.to(device)\n",
    "        \n",
    "        y_pred = model(X_dev, X_time_home_dev)\n",
    "        \n",
    "        batch_loss_sum = float(\n",
    "            nn.BCELoss(reduction='sum')(y_pred, y_dev.float())\n",
    "        )\n",
    "        dev_loss_total += batch_loss_sum\n",
    "        \n",
    "    loss = dev_loss_total / len(commentary_dev_plus)\n",
    "    dev_losses.append(loss)\n",
    "    \n",
    "    print(f'Epoch: {epoch+1}, train_loss: {training_losses[-1]}, dev_loss: {dev_losses[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "pd.DataFrame({'train': training_losses, 'dev': dev_losses}).plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for data in DataLoader(commentary_train_plus, batch_size=256):\n",
    "    X_train, X_time_home_train, y_train = data\n",
    "    X_train, X_time_home_train, y_train = X_train.to(device), X_time_home_train.to(device), y_train.to(device)\n",
    "\n",
    "    y_pred = model(X_train, X_time_home_train)\n",
    "    \n",
    "    y_train_list.append(y_train.detach().cpu().numpy())\n",
    "    y_pred_list.append(y_pred.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.concatenate(y_train_list, axis=0)\n",
    "y_pred = np.concatenate(y_pred_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7053438363124321"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dev ROCAUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev_list = []\n",
    "y_pred_list = []\n",
    "\n",
    "for data in DataLoader(commentary_dev_plus, batch_size=256):\n",
    "    X_dev, X_time_home_dev, y_dev = data\n",
    "    X_dev, X_time_home_dev, y_dev = X_dev.to(device), X_time_home_dev.to(device), y_dev.to(device)\n",
    "\n",
    "    y_pred = model(X_dev, X_time_home_dev)\n",
    "    \n",
    "    y_dev_list.append(y_dev.detach().cpu().numpy())\n",
    "    y_pred_list.append(y_pred.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_dev = np.concatenate(y_dev_list, axis=0)\n",
    "y_pred = np.concatenate(y_pred_list, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.626376404819081"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_dev, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Overfitting more of an issue when minutes and home team features are added\n",
    "- Better training ROCAUC\n",
    "- Worse dev ROCAUC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
