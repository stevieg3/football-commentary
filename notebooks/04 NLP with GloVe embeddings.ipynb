{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP with GloVe embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/stevengeorge/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pre-trained GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.64 s, sys: 265 ms, total: 7.91 s\n",
      "Wall time: 7.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "word_to_vector = {}\n",
    "with open('data/external/GloVe/glove.6B/glove.6B.100d.txt', \"r\") as f:\n",
    "    # Each line starts with the word/character followed by the 100d vector representation\n",
    "    for line in f:  # itertools.islice(f, 5):\n",
    "        \n",
    "        # Split by whitespace:\n",
    "        components = line.split()\n",
    "        \n",
    "        word = components[0]\n",
    "        vector_values = components[1:]\n",
    "        \n",
    "        vector_array = np.array(vector_values, dtype=np.float64)  # Convert vector to numpy array\n",
    "        \n",
    "        # Add to dictionary\n",
    "        word_to_vector[word] = vector_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load training and dev data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(749640, 13)\n",
      "(92689, 13)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_parquet('data/processed/train.parquet')\n",
    "print(train.shape)\n",
    "\n",
    "dev = pd.read_parquet('data/processed/dev.parquet')\n",
    "print(dev.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>sort_order</th>\n",
       "      <th>time</th>\n",
       "      <th>text</th>\n",
       "      <th>event_type</th>\n",
       "      <th>event_team</th>\n",
       "      <th>opponent</th>\n",
       "      <th>is_goal</th>\n",
       "      <th>assist_method</th>\n",
       "      <th>fast_break</th>\n",
       "      <th>season</th>\n",
       "      <th>country</th>\n",
       "      <th>event_team_was_home</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Attempt missed. Mladen Petric (Hamburg) left f...</td>\n",
       "      <td>Attempt</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>0</td>\n",
       "      <td>Pass</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Corner,  Borussia Dortmund. Conceded by Dennis...</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>Corner,  Borussia Dortmund. Conceded by Heiko ...</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>Foul by Sven Bender (Borussia Dortmund).</td>\n",
       "      <td>Foul</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UFot0hit/</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>Gokhan Tore (Hamburg) wins a free kick in the ...</td>\n",
       "      <td>Free kick won</td>\n",
       "      <td>Hamburg SV</td>\n",
       "      <td>Borussia Dortmund</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>2012</td>\n",
       "      <td>germany</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp  sort_order  time  \\\n",
       "0  UFot0hit/           1     2   \n",
       "1  UFot0hit/           2     4   \n",
       "2  UFot0hit/           3     4   \n",
       "3  UFot0hit/           4     7   \n",
       "4  UFot0hit/           5     7   \n",
       "\n",
       "                                                text     event_type  \\\n",
       "0  Attempt missed. Mladen Petric (Hamburg) left f...        Attempt   \n",
       "1  Corner,  Borussia Dortmund. Conceded by Dennis...         Corner   \n",
       "2  Corner,  Borussia Dortmund. Conceded by Heiko ...         Corner   \n",
       "3           Foul by Sven Bender (Borussia Dortmund).           Foul   \n",
       "4  Gokhan Tore (Hamburg) wins a free kick in the ...  Free kick won   \n",
       "\n",
       "          event_team           opponent  is_goal assist_method  fast_break  \\\n",
       "0         Hamburg SV  Borussia Dortmund        0          Pass           0   \n",
       "1  Borussia Dortmund         Hamburg SV        0          None           0   \n",
       "2  Borussia Dortmund         Hamburg SV        0          None           0   \n",
       "3  Borussia Dortmund         Hamburg SV        0          None           0   \n",
       "4         Hamburg SV  Borussia Dortmund        0          None           0   \n",
       "\n",
       "   season  country  event_team_was_home  \n",
       "0    2012  germany                    0  \n",
       "1    2012  germany                    1  \n",
       "2    2012  germany                    1  \n",
       "3    2012  germany                    1  \n",
       "4    2012  germany                    0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Remove `time` and `event_team_was_home` for now but may want to add these back as they are not extracted from the text itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_for_nlp(df):\n",
    "    \n",
    "    df = df.copy()\n",
    "    \n",
    "    # Sort by event order\n",
    "    df.sort_values(['id_odsp', 'sort_order'], inplace=True)\n",
    "    # Create target\n",
    "    df['next_event_is_goal'] = df.groupby('id_odsp')['is_goal'].shift(-1)\n",
    "    # Drop redundant columns\n",
    "    df.drop(\n",
    "        columns=['sort_order', 'event_type', 'event_team', 'opponent', 'is_goal', 'assist_method', 'fast_break', 'season', 'country', 'event_team_was_home', 'time'], \n",
    "        inplace=True\n",
    "    )\n",
    "    # Drop entries with null target due to -1 shift\n",
    "    df.dropna(subset=['next_event_is_goal'], axis=0, inplace=True)\n",
    "    \n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p = process_data_for_nlp(train)\n",
    "dev_p = process_data_for_nlp(dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>text</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Bafetimbi Gomis (Swansea City) wins a free kic...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Foul by Maya Yoshida (Southampton).</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Dusan Tadic (Southampton) wins a free kick on ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Foul by Neil Taylor (Swansea City).</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Attempt saved. James Ward-Prowse (Southampton)...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp                                               text  \\\n",
       "0  004f4ING/  Bafetimbi Gomis (Swansea City) wins a free kic...   \n",
       "1  004f4ING/                Foul by Maya Yoshida (Southampton).   \n",
       "2  004f4ING/  Dusan Tadic (Southampton) wins a free kick on ...   \n",
       "3  004f4ING/                Foul by Neil Taylor (Swansea City).   \n",
       "4  004f4ING/  Attempt saved. James Ward-Prowse (Southampton)...   \n",
       "\n",
       "   next_event_is_goal  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>text</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>Foul by Juan Manuel FalcA³n (Metz).</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>TiemouA© Bakayoko (Monaco) wins a free kick in...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>Foul by Anthony Martial (Monaco).</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>Sylvain Marchal (Metz) wins a free kick in the...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00nmICd9/</td>\n",
       "      <td>Foul by Cheick Doukoure (Metz).</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp                                               text  \\\n",
       "0  00nmICd9/                Foul by Juan Manuel FalcA³n (Metz).   \n",
       "1  00nmICd9/  TiemouA© Bakayoko (Monaco) wins a free kick in...   \n",
       "2  00nmICd9/                  Foul by Anthony Martial (Monaco).   \n",
       "3  00nmICd9/  Sylvain Marchal (Metz) wins a free kick in the...   \n",
       "4  00nmICd9/                    Foul by Cheick Doukoure (Metz).   \n",
       "\n",
       "   next_event_is_goal  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_p.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize text commentary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GloVe we are using is uncased so change all text to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_p['text_lowercase'] = train_p['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 47s, sys: 751 ms, total: 1min 48s\n",
      "Wall time: 1min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_p['text_split'] = train_p['text_lowercase'].apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_odsp</th>\n",
       "      <th>text</th>\n",
       "      <th>next_event_is_goal</th>\n",
       "      <th>text_lowercase</th>\n",
       "      <th>text_split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Bafetimbi Gomis (Swansea City) wins a free kic...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>bafetimbi gomis (swansea city) wins a free kic...</td>\n",
       "      <td>[bafetimbi, gomis, (, swansea, city, ), wins, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Foul by Maya Yoshida (Southampton).</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by maya yoshida (southampton).</td>\n",
       "      <td>[foul, by, maya, yoshida, (, southampton, ), .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Dusan Tadic (Southampton) wins a free kick on ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>dusan tadic (southampton) wins a free kick on ...</td>\n",
       "      <td>[dusan, tadic, (, southampton, ), wins, a, fre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Foul by Neil Taylor (Swansea City).</td>\n",
       "      <td>0.0</td>\n",
       "      <td>foul by neil taylor (swansea city).</td>\n",
       "      <td>[foul, by, neil, taylor, (, swansea, city, ), .]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>004f4ING/</td>\n",
       "      <td>Attempt saved. James Ward-Prowse (Southampton)...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>attempt saved. james ward-prowse (southampton)...</td>\n",
       "      <td>[attempt, saved, ., james, ward-prowse, (, sou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id_odsp                                               text  \\\n",
       "0  004f4ING/  Bafetimbi Gomis (Swansea City) wins a free kic...   \n",
       "1  004f4ING/                Foul by Maya Yoshida (Southampton).   \n",
       "2  004f4ING/  Dusan Tadic (Southampton) wins a free kick on ...   \n",
       "3  004f4ING/                Foul by Neil Taylor (Swansea City).   \n",
       "4  004f4ING/  Attempt saved. James Ward-Prowse (Southampton)...   \n",
       "\n",
       "   next_event_is_goal                                     text_lowercase  \\\n",
       "0                 0.0  bafetimbi gomis (swansea city) wins a free kic...   \n",
       "1                 0.0                foul by maya yoshida (southampton).   \n",
       "2                 0.0  dusan tadic (southampton) wins a free kick on ...   \n",
       "3                 0.0                foul by neil taylor (swansea city).   \n",
       "4                 0.0  attempt saved. james ward-prowse (southampton)...   \n",
       "\n",
       "                                          text_split  \n",
       "0  [bafetimbi, gomis, (, swansea, city, ), wins, ...  \n",
       "1    [foul, by, maya, yoshida, (, southampton, ), .]  \n",
       "2  [dusan, tadic, (, southampton, ), wins, a, fre...  \n",
       "3   [foul, by, neil, taylor, (, swansea, city, ), .]  \n",
       "4  [attempt, saved, ., james, ward-prowse, (, sou...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length = train_p['text_split'].apply(len).max()\n",
    "max_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assume that items which are not in the GloVe matrix are player names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742443"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_p.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zero_pad(unpadded_matrix, max_length):\n",
    "    \n",
    "    if unpadded_matrix.shape[1] < max_length:\n",
    "        num_missing_items = max_length - unpadded_matrix.shape[1]\n",
    "        zero_pad = np.zeros((unpadded_matrix.shape[0], num_missing_items))\n",
    "\n",
    "    padded_matrix = np.concatenate((unpadded_matrix, zero_pad), axis=1)\n",
    "    \n",
    "    return padded_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = train_p.shape[0]\n",
    "\n",
    "train_3d = np.zeros((50, m, 100))  # seq_len, examples, input_size\n",
    "\n",
    "unknown_items = []  # Keep track of items not in GloVe\n",
    "\n",
    "for i, row in train_p.iterrows():\n",
    "    text_split = row['text_split']  # List of items in text commentary\n",
    "    \n",
    "    vector_list = []\n",
    "    for item in text_split:\n",
    "        try:\n",
    "            word_vector = word_to_vector[item].reshape(100, 1)  # Get GloVe vector for item\n",
    "            vector_list.append(word_vector)\n",
    "        except KeyError:\n",
    "            unknown_items.append(item)  # Add to unknown list\n",
    "            word_vector = word_to_vector['name'].reshape(100, 1)  # Substitute unknown item with vector for 'name'\n",
    "    \n",
    "    text_commentary_matrix = np.concatenate(vector_list, axis=1)  # Concanenate vectors into a matrix of dim (100, num_items)\n",
    "    text_commentary_matrix = zero_pad(text_commentary_matrix, max_length=max_length)  # zero-padding to (100, 50)\n",
    "    \n",
    "    train_3d[:, i, :] = text_commentary_matrix.T  # Add to 3D input matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1884"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(unknown_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 742443, 100)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_3d.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## y labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train_p['next_event_is_goal'].values\n",
    "y_dev = dev_p['next_event_is_goal'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create PyTorch custom dataset\n",
    "\n",
    "https://pytorch.org/tutorials/beginner/data_loading_tutorial.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentaryDataset(Dataset):\n",
    "\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "        :param X: 3D numpy array (seq_len, examples, input_size)\n",
    "        :param y: Labels\n",
    "        \"\"\"\n",
    "        self.X = X\n",
    "        self.y = y.reshape(-1, 1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[1]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        return self.X[:, idx, :], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_comm = CommentaryDataset(X=train_3d, y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.CommentaryDataset at 0x7f7fbcf31c10>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_comm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 742443, 100)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_3d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "742443"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_comm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_num_threads(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_num_threads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(train_comm, batch_size=256, num_workers=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommentaryClassifier(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(CommentaryClassifier, self).__init__()\n",
    "        # LSTM\n",
    "        self.lstm = nn.LSTM(input_size=100, hidden_size=10)\n",
    "        # MLPs\n",
    "#         self.fc_1 = nn.Linear(in_features=30, out_features=20)\n",
    "        self.fc_2 = nn.Linear(in_features=10, out_features=1)\n",
    "        # Activation functions\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        all_h_t, _ = self.lstm(x.float())\n",
    "        h_T = all_h_t[:, -1, :]  # Final cell outputs\n",
    "#         x = self.fc_1(h_T)\n",
    "#         x = self.relu(x)\n",
    "        x = self.fc_2(h_T)\n",
    "        x = self.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "commentary_model = CommentaryClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CommentaryClassifier(\n",
      "  (lstm): LSTM(100, 10)\n",
      "  (fc_2): Linear(in_features=10, out_features=1, bias=True)\n",
      "  (relu): ReLU()\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(commentary_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimiser = optim.Adam(params=commentary_model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "tensor(0.8488, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "50\n",
      "tensor(0.6706, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "100\n",
      "tensor(0.2989, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "150\n",
      "tensor(0.2309, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "200\n",
      "tensor(0.1327, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "250\n",
      "tensor(0.0987, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "300\n",
      "tensor(0.1119, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "350\n",
      "tensor(0.1454, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "400\n",
      "tensor(0.1970, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "450\n",
      "tensor(0.1175, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "500\n",
      "tensor(0.1305, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "550\n",
      "tensor(0.1218, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "600\n",
      "tensor(0.1581, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "650\n",
      "tensor(0.1440, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "700\n",
      "tensor(0.1159, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "750\n",
      "tensor(0.1013, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "800\n",
      "tensor(0.1082, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "850\n",
      "tensor(0.1153, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "900\n",
      "tensor(0.0577, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "950\n",
      "tensor(0.1007, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1000\n",
      "tensor(0.0832, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1050\n",
      "tensor(0.1295, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1100\n",
      "tensor(0.1150, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1150\n",
      "tensor(0.1020, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1200\n",
      "tensor(0.1005, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1250\n",
      "tensor(0.1002, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1300\n",
      "tensor(0.2138, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1350\n",
      "tensor(0.1994, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1400\n",
      "tensor(0.0716, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1450\n",
      "tensor(0.1146, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1500\n",
      "tensor(0.1118, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1550\n",
      "tensor(0.1857, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1600\n",
      "tensor(0.1860, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1650\n",
      "tensor(0.1160, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1700\n",
      "tensor(0.0855, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1750\n",
      "tensor(0.1428, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1800\n",
      "tensor(0.0851, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1850\n",
      "tensor(0.1574, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1900\n",
      "tensor(0.1420, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "1950\n",
      "tensor(0.0996, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2000\n",
      "tensor(0.1426, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2050\n",
      "tensor(0.1424, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2100\n",
      "tensor(0.0992, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2150\n",
      "tensor(0.1137, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2200\n",
      "tensor(0.1564, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2250\n",
      "tensor(0.1423, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2300\n",
      "tensor(0.0708, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2350\n",
      "tensor(0.0713, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2400\n",
      "tensor(0.1277, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2450\n",
      "tensor(0.1134, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2500\n",
      "tensor(0.0849, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2550\n",
      "tensor(0.0989, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2600\n",
      "tensor(0.1276, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2650\n",
      "tensor(0.0576, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2700\n",
      "tensor(0.0846, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2750\n",
      "tensor(0.1133, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2800\n",
      "tensor(0.1132, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2850\n",
      "tensor(0.1132, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "2900\n",
      "tensor(0.2910, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "0\n",
      "tensor(0.1133, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "50\n",
      "tensor(0.1132, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "100\n",
      "tensor(0.0880, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "150\n",
      "tensor(0.1841, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "200\n",
      "tensor(0.0848, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "250\n",
      "tensor(0.0697, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "300\n",
      "tensor(0.0986, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "350\n",
      "tensor(0.1416, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "400\n",
      "tensor(0.1988, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "450\n",
      "tensor(0.1129, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "500\n",
      "tensor(0.1271, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "550\n",
      "tensor(0.1250, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "600\n",
      "tensor(0.1553, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "650\n",
      "tensor(0.1410, grad_fn=<BinaryCrossEntropyBackward>)\n",
      "700\n",
      "tensor(0.1128, grad_fn=<BinaryCrossEntropyBackward>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-66-591ecc6d6d76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0moptimiser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/football-commentary/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/football-commentary/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "\n",
    "    for i, data in enumerate(data_loader):\n",
    "        \n",
    "        X, y = data\n",
    "\n",
    "        optimiser.zero_grad()  # Set gradients to 0 otherwise will accumulate\n",
    "\n",
    "        y_pred = commentary_model(X)\n",
    "        loss = criterion(y_pred, y.float())\n",
    "        if i % 50 == 0:\n",
    "            print(i)\n",
    "            print(loss)\n",
    "        loss.backward()\n",
    "        optimiser.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "- How to deal with player names when using pretrained weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO\n",
    "\n",
    "- Change CSV read method so name accents correctly imported"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
